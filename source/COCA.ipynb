{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bDPuEo5aI0U4","outputId":"ca8f6fb5-3258-49bd-df1f-3dce7c13d92c","executionInfo":{"status":"ok","timestamp":1712107821011,"user_tz":-420,"elapsed":82801,"user":{"displayName":"Minh H","userId":"01179143856582604111"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting coca-pytorch\n","  Downloading CoCa_pytorch-0.1.0-py3-none-any.whl (7.0 kB)\n","Collecting einops>=0.4 (from coca-pytorch)\n","  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from coca-pytorch) (2.2.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->coca-pytorch) (3.13.3)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->coca-pytorch) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->coca-pytorch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->coca-pytorch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->coca-pytorch) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->coca-pytorch) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.6->coca-pytorch)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.6->coca-pytorch)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.6->coca-pytorch)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.6->coca-pytorch)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.6->coca-pytorch)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.6->coca-pytorch)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.6->coca-pytorch)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.6->coca-pytorch)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.6->coca-pytorch)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.6->coca-pytorch)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.6->coca-pytorch)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->coca-pytorch) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6->coca-pytorch)\n","  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->coca-pytorch) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->coca-pytorch) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, einops, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, coca-pytorch\n","Successfully installed coca-pytorch-0.1.0 einops-0.7.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105\n"]}],"source":["!pip install coca-pytorch"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"1annJ85mJI5_","executionInfo":{"status":"ok","timestamp":1712107827837,"user_tz":-420,"elapsed":6839,"user":{"displayName":"Minh H","userId":"01179143856582604111"}}},"outputs":[],"source":["!pip install vit-pytorch>=0.40.2"]},{"cell_type":"code","source":["import torch\n","\n","# import vision transformer\n","\n","from vit_pytorch.simple_vit_with_patch_dropout import SimpleViT\n","from vit_pytorch.extractor import Extractor\n","\n","vit = SimpleViT(\n","    image_size = 256,\n","    patch_size = 32,\n","    num_classes = 1000,\n","    dim = 1024,\n","    depth = 6,\n","    heads = 16,\n","    mlp_dim = 2048,\n","    patch_dropout = 0.5  # https://arxiv.org/abs/2212.00794\n",")\n","\n","vit = Extractor(vit, return_embeddings_only = True, detach = False)\n","\n","# extractor will enable it so the vision transformer returns its embeddings\n","\n","# import CoCa and instantiate it\n","\n","from coca_pytorch.coca_pytorch import CoCa\n","\n","coca = CoCa(\n","    dim = 512,                     # model dimension\n","    img_encoder = vit,             # vision transformer - image encoder, returning image embeddings as (batch, seq, dim)\n","    image_dim = 1024,              # image embedding dimension, if not the same as model dimensions\n","    num_tokens = 20000,            # number of text tokens\n","    unimodal_depth = 6,            # depth of the unimodal transformer\n","    multimodal_depth = 6,          # depth of the multimodal transformer\n","    dim_head = 64,                 # dimension per attention head\n","    heads = 8,                     # number of attention heads\n","    caption_loss_weight = 1.,      # weight on the autoregressive caption loss\n","    contrastive_loss_weight = 1.,  # weight on the contrastive loss between image and text CLS embeddings\n",").cuda()\n","\n","# mock text and images\n","\n","text = torch.randint(0, 20000, (4, 512)).cuda()\n","images = torch.randn(4, 3, 256, 256).cuda()\n","\n","# train by giving CoCa your text and images with `return_loss = True`\n","\n","loss = coca(\n","    text = text,\n","    images = images,\n","    return_loss = True  # set this to True to get the full caption + contrastive loss\n",")\n","\n","loss.backward()\n","\n","# do the above for as much text and images...\n","# then you can get the caption logits as so\n","\n","logits = coca(\n","    text = text,\n","    images = images\n",") # (4, 512, 20000)\n","\n","# and the CLIP-like text and image embeddings as\n","\n","text_embeds, image_embeds = coca(\n","    text = text,\n","    images = images,\n","    return_embeddings = True\n",") # (4, 512), (4, 512)"],"metadata":{"id":"m24Qkb-9vxIF","executionInfo":{"status":"ok","timestamp":1712107840545,"user_tz":-420,"elapsed":12711,"user":{"displayName":"Minh H","userId":"01179143856582604111"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["print(\"Loss after training:\", loss.item())\n","print(\"Caption Logits shape:\", logits.shape)\n","print(\"Text Embeddings shape:\", text_embeds.shape)\n","print(\"Image Embeddings shape:\", image_embeds.shape)\n"],"metadata":{"id":"mwD0fa82gHPm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712107840546,"user_tz":-420,"elapsed":5,"user":{"displayName":"Minh H","userId":"01179143856582604111"}},"outputId":"887cea15-7c0b-49fe-a038-8b0663f90d73"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Loss after training: 11.41302490234375\n","Caption Logits shape: torch.Size([4, 512, 20000])\n","Text Embeddings shape: torch.Size([4, 512])\n","Image Embeddings shape: torch.Size([4, 512])\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}